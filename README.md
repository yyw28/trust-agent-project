1. get interface by running local code: /Users/yuwenyu/trust-agent-project-2, 
2. next step, fine-tune BERT and HuBert with subsets of my dataset to have the classifier works better?
3. train with my datasets using two options: 1. RL 2. professional prompting: inject findings/patterns I have from my survey experiments.
4. comparing which method (1)basic prompting: no knowledge inject, (2)professional prompting: GLM results, (3)RL with our data, which one is better (overall, which method generated higher trustworhty results)?
